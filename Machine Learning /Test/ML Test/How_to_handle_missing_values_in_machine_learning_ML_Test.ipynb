{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kaPhQ4pevyt",
        "outputId": "1f48baba-195e-40d4-eaaf-e56eb58556f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset with missing values:\n",
            "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
            "0   0.496714  -0.138264   0.647689        NaN  -0.234153  -0.234137   \n",
            "1  -0.463418  -0.465730   0.241962  -1.913280  -1.724918  -0.562288   \n",
            "2   1.465649  -0.225776   0.067528  -1.424748  -0.544383   0.110923   \n",
            "3  -0.601707   1.852278  -0.013497  -1.057711   0.822545  -1.220844   \n",
            "4   0.738467   0.171368  -0.115648  -0.301104  -1.478522        NaN   \n",
            "\n",
            "   feature_6  feature_7  feature_8  feature_9  \n",
            "0   1.579213   0.767435  -0.469474   0.542560  \n",
            "1  -1.012831   0.314247  -0.908024  -1.412304  \n",
            "2  -1.150994   0.375698  -0.600639  -0.291694  \n",
            "3   0.208864  -1.959670  -1.328186   0.196861  \n",
            "4  -0.460639   1.057122   0.343618  -1.763040  \n",
            "\n",
            "Dataset after removing rows with missing values:\n",
            "    feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
            "1   -0.463418  -0.465730   0.241962  -1.913280  -1.724918  -0.562288   \n",
            "2    1.465649  -0.225776   0.067528  -1.424748  -0.544383   0.110923   \n",
            "3   -0.601707   1.852278  -0.013497  -1.057711   0.822545  -1.220844   \n",
            "12   0.791032  -0.909387   1.402794  -1.401851   0.586857   2.190456   \n",
            "18   0.625667  -0.857158  -1.070892   0.482472  -0.223463   0.714000   \n",
            "\n",
            "    feature_6  feature_7  feature_8  feature_9  \n",
            "1   -1.012831   0.314247  -0.908024  -1.412304  \n",
            "2   -1.150994   0.375698  -0.600639  -0.291694  \n",
            "3    0.208864  -1.959670  -1.328186   0.196861  \n",
            "12  -0.990536  -0.566298   0.099651  -0.503476  \n",
            "18   0.473238  -0.072829  -0.846794  -1.514847  \n",
            "\n",
            "Dataset after imputing missing values with mean:\n",
            "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
            "0   0.496714  -0.138264   0.647689   0.091885  -0.234153  -0.234137   \n",
            "1  -0.463418  -0.465730   0.241962  -1.913280  -1.724918  -0.562288   \n",
            "2   1.465649  -0.225776   0.067528  -1.424748  -0.544383   0.110923   \n",
            "3  -0.601707   1.852278  -0.013497  -1.057711   0.822545  -1.220844   \n",
            "4   0.738467   0.171368  -0.115648  -0.301104  -1.478522  -0.031146   \n",
            "\n",
            "   feature_6  feature_7  feature_8  feature_9  \n",
            "0   1.579213   0.767435  -0.469474   0.542560  \n",
            "1  -1.012831   0.314247  -0.908024  -1.412304  \n",
            "2  -1.150994   0.375698  -0.600639  -0.291694  \n",
            "3   0.208864  -1.959670  -1.328186   0.196861  \n",
            "4  -0.460639   1.057122   0.343618  -1.763040  \n",
            "\n",
            "Accuracy after handling missing values: 0.5\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create a synthetic dataset with missing values\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 10)\n",
        "y = np.random.randint(0, 2, 100)\n",
        "\n",
        "# Introduce missing values in the dataset\n",
        "X[np.random.choice([True, False], size=X.shape, p=[0.1, 0.9])] = np.nan\n",
        "\n",
        "# Convert to DataFrame for convenience\n",
        "X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(10)])\n",
        "y = pd.Series(y, name='target')\n",
        "\n",
        "print(\"Dataset with missing values:\")\n",
        "print(X.head())\n",
        "\n",
        "# Method 1: Remove rows with missing values\n",
        "X_dropped = X.dropna()\n",
        "y_dropped = y[X_dropped.index]\n",
        "\n",
        "print(\"\\nDataset after removing rows with missing values:\")\n",
        "print(X_dropped.head())\n",
        "\n",
        "# Method 2: Impute missing values with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "print(\"\\nDataset after imputing missing values with mean:\")\n",
        "print(X_imputed.head())\n",
        "\n",
        "# Split the data into training and testing sets (using imputed dataset for further steps)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the SVM model\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"\\nAccuracy after handling missing values:\", accuracy)\n"
      ]
    }
  ]
}